# Generating Handwritten Digit Images using DCGAN

This project demonstrates the generation of handwritten digit images using a **Deep Convolutional Generative Adversarial Network (DCGAN)**. The model is trained on the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits (0-9). Over the course of training, the generator network learns to create images that mimic the real handwritten digits from the dataset.

## Project Overview

The goal of this project is to train a DCGAN that can generate realistic images of handwritten digits. The project follows a typical Generative Adversarial Network (GAN) architecture that consists of two main components:

1. **Generator**: Takes random noise as input and generates synthetic images (in this case, handwritten digits).
2. **Discriminator**: Classifies images as either real (from the MNIST dataset) or fake (generated by the generator).

Through a process of competition between the generator and discriminator, both models improve over time. The generator aims to create images that are increasingly convincing, while the discriminator learns to better distinguish between real and fake images.

## üß† How the Model Works

### 1. **Data Preprocessing**
The MNIST dataset is loaded and preprocessed by reshaping the images to 28x28 pixels and normalizing the pixel values to a range of [-1, 1]. This normalization is important for the performance of the GAN during training.

### 2. **Generator Model**
The generator takes random noise as input and transforms it into an image resembling a handwritten digit. It uses a series of **dense layers**, **batch normalization**, and **transposed convolutions** to progressively upscale the random noise into a 28x28x1 image.

### 3. **Discriminator Model**
The discriminator is trained to differentiate between real and generated images. It uses **convolutional layers** followed by **leaky ReLU activations** and **dropout layers** to classify whether an image is real or fake. The output is a binary decision: real (1) or fake (0).

### 4. **Loss Functions**
The **discriminator loss** quantifies how well the discriminator distinguishes between real and fake images. The **generator loss** measures how well the generator can fool the discriminator into thinking its fake images are real. Both losses are based on binary cross-entropy.

### 5. **Training**
During training, the generator and discriminator are updated alternately. The generator tries to improve its ability to create realistic images, while the discriminator gets better at telling real from fake images. The training process is iterative and continues until the generator produces realistic images that are hard for the discriminator to distinguish from real ones.

### 6. **Visualization of Progress**
To visualize the model's progress, images are generated and saved all key epochs. These images show the transformation of the generator's output from random noise into recognizable handwritten digits as training progresses.

An animated **GIF** (`dcgan.gif`) is also created, which combines all these images, allowing you to see the gradual improvement in image quality over time.

## üìÅ Directory Structure

The project contains the following structure:

- **Checkpoints/**: Contains model checkpoint files, saved during training.
- **Epoch_Images/**: Stores the images generated after all epochs.
- **Generate_handwritten_digit_images_DCGAN.ipynb**: Jupyter notebook containing the code to generate and train the model.
- **dcgan.gif**: The animated GIF showing the evolution of the generated images over the course of training.

## üìä Results

The results can be visualized in two ways:

1. **Epoch Images**: Images generated after all training epochsare saved in the **Epoch_Images/** directory. These images show the progression of the generator‚Äôs output from random noise to realistic digit images.

2. **Animated GIF**: The file **dcgan.gif** showcases the gradual improvement in generated images. It combines the images from all epochs and provides a clear visual representation of how the generator improves over time.

## üñ• Accessing the Results on Your Computer

To access and view the generated images:

1. Open the **`Generate_handwritten_digit_images_DCGAN.ipynb`** Jupyter notebook and run the necessary cells to train the model.
2. After training, check the **Epoch_Images/** folder for the images saved at various epochs.
3. To see the progress as an animation, you can view the **dcgan.gif** file. This GIF shows the generated images from different epochs and highlights the improvement in quality.

For example, to view an image from a specific epoch, navigate to the **Epoch_Images/** folder and open the image corresponding to that epoch (e.g., `image_at_epoch_0100.png`).

### Example:

- The image generated after **epoch 100** can be accessed by opening the file `Epoch_Images/image_at_epoch_0100.png`.
- To view the training progress, open the **dcgan.gif** file. It will show the evolution of the generated images from random noise to realistic digit images over time.

## üîÑ How to Run the Code

To run this project on your own machine, follow these steps:

1. **Clone the repository**: Download the project or clone it to your local machine.
2. **Install dependencies**: Make sure to install the required dependencies listed at the beginning of the notebook.
3. **Run the Jupyter notebook**: Open the **`Generate_handwritten_digit_images_DCGAN.ipynb`** file in a Jupyter notebook environment and execute the cells to start training the model.
4. **View the results**: After training completes, check the **Epoch_Images/** folder for the generated images and view the **dcgan.gif** for an animated overview of the progress.

## üìù License

The code and methodology are inspired by the [official TensorFlow DCGAN tutorial](https://www.tensorflow.org/tutorials/generative/dcgan), which has been modified to suit the specific task of generating handwritten digits from the MNIST dataset.

---

Feel free to clone or download the repository, experiment with the model, and start generating your own handwritten digit images! üòä
